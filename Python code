# Import Libraries
import pandas as pd  # Data manipulation
import matplotlib.pyplot as plt  # Data visualization
import seaborn as sns  # Data visualization
defining
from sklearn import metrics  # Model evaluation
from sklearn.neighbors import KNeighborsClassifier  # KNN Model
from sklearn.linear_model import LogisticRegression  # Logistic Regression Model
from sklearn.model_selection import train_test_split  # Data splitting

# Load and preprocess the dataset
COLUMN_NAMES = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']
iris_data = pd.read_csv('IRIS.csv', names=COLUMN_NAMES)

# Convert columns to numeric types and handle errors
for col in ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']:
    iris_data[col] = pd.to_numeric(iris_data[col], errors='coerce')

# Drop the first row (if necessary)
iris_data = iris_data[1:].reset_index(drop=True)

# Feature matrix and target variable
X = iris_data.drop(columns=['class'])
y = iris_data['class']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=5)

# K-Nearest Neighbors: Experimenting with different k values
k_range = range(1, 26)
scores = []

for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(X_train, y_train)
    y_pred = knn.predict(X_test)
    scores.append(metrics.accuracy_score(y_test, y_pred))

# Plot accuracy scores for different k values
plt.figure(figsize=(10, 6))
plt.plot(k_range, scores, marker='o')
plt.xlabel('Value of k for KNN')
plt.ylabel('Accuracy Score')
plt.title('Accuracy Scores for K-Nearest Neighbors (k values)')
plt.grid()
plt.show()

# Logistic Regression
logreg = LogisticRegression(max_iter=200)
logreg.fit(X_train, y_train)
y_pred_logreg = logreg.predict(X_test)
logreg_accuracy = metrics.accuracy_score(y_test, y_pred_logreg)
print(f"Logistic Regression Accuracy: {logreg_accuracy:.2f}")

# Choosing KNN with optimal k (e.g., k=12)
optimal_k = 12
knn_final = KNeighborsClassifier(n_neighbors=optimal_k)
knn_final.fit(X, y)

# Prediction with KNN model
sample_observation = [[5.5, 3.3, 1.3, 0.2]]
predicted_class = knn_final.predict(sample_observation)
print(f"Predicted class for {sample_observation}: {predicted_class[0]}")
